{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Final\n",
    "\n",
    "Enhorabuena!!! Ya el haber llegado hasta aquí es un logro más en tu camino para ser un experto del Big Data y del Machine Learning!! \n",
    "\n",
    "\n",
    "<img src=\"./Images/happy.gif\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Con esta práctica pondremos en valor todo lo que hemos visto a lo largo del módulo. Vamos allá!! 😄"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Multiconjuntos\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad resolver un problema usando vectores.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python`\n",
    "- Asegurar los fundamentos matemáticos detrás de las operaciones con conjuntos.\n",
    "\n",
    "**Problema**: Implementar las operaciones de los multiconjuntos (utilizando las librerías y estructuras de datos vistas en el curso).\n",
    "\n",
    "**Datos:**\n",
    "\n",
    "Un multiconjunto es un conjunto en el que un elemento puede repetirse, es decir, cada elemento posee una multiplicidad (un número natural) que indica cuántas veces el elemento es miembro del conjunto. Por ejemplo, en el multiconjunto `{a, a, b, b, b, c}`, las multiplicidades de los miembros a, b, y c son 2, 3, y 1, respectivamente.\n",
    "\n",
    "Al igual que los conjuntos, poseen las siguientes características y operaciones:\n",
    "- Cardinalidad: indica el número de elementos del multiconjunto. Por ejemplo, la cardinalidad del multiconjunto `{a, a, b, b, b, c}` es 6 (la suma de sus multiplicidades).\n",
    "- Inserción: permite insertar una ocurrencia de un elemento en el multiconjunto.\n",
    "- Eliminación: permite eliminar una ocurrencia de un elemento del multiconjunto.\n",
    "- Comparación: compara dos multiconjuntos para determinar si son iguales.\n",
    "- Pertenencia: determina si un elemento pertenece al multiconjunto.\n",
    "- Subconjunto: determina si un multiconjunto es subconjunto de otro.\n",
    "- Unión: conjunción de todos los elementos de dos multiconjuntos (sumando sus multiplicidades si un elementos está en los dos).\n",
    "- Intersección: elementos que están en los dos multiconjuntos quedándonos con la multiplicidad más pequeña.\n",
    "- Diferencia: restar a un multiconjunto los elementos de otro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dada una lista devuelva un multiconjunto\n",
    "### El multiconjunto que devuelve puede crearse con la estructura de datos que se quiera (incluso una lista)\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "elementos = [1 , 1 , 2 , 3 , 4 , 3 , 2 , 1 , 4 ,3 , 5]\n",
    "\n",
    "def multiconjunto(elementos):\n",
    "    multiplicidad={}\n",
    "    \n",
    "    for n in elementos:\n",
    "        if n in multiplicidad:\n",
    "            multiplicidad[n] += 1\n",
    "        else :\n",
    "            multiplicidad[n]=1\n",
    "                \n",
    "    print (multiplicidad)\n",
    "\n",
    "mc=multiconjunto(elementos)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto devuelva su cardinalidad\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def cardinalidad(multiconjunto):\n",
    "    \n",
    "    for n in elementos:\n",
    "        return len(elementos)\n",
    "    \n",
    "\n",
    "cardinalidad(mc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva el multiconjunto con el elemento insertado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "for i in range(len (mc)):\n",
    "    print(mc[i])\n",
    "def h(e):\n",
    "    return hash(e) % 2096\n",
    "\n",
    "def inserta(elemento, multiconjunto):\n",
    "    \n",
    "    posicion = h(elemento)\n",
    "    \n",
    "    if elemento not in multiconjunto[posicion]:\n",
    "        \n",
    "        multiconjunto[posicion].add(elemento)\n",
    "        return multiconjunto\n",
    "    \n",
    "mc = inserta(9, mc)\n",
    "mc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva el multiconjunto con el elemento eliminado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def elimina(multiconjunto, elemento):\n",
    "    \"\"\"\n",
    "    Devuelve el multiconjunto habiendo eliminado una ocurrencia del elemento dado\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "        elemento -- elemento a eliminar\n",
    "    \"\"\"\n",
    "    \n",
    "    if not((multiconjunto, elemento)):\n",
    "        print(f'El elemento {elemento} no pertenece al conjunto. No se ha podido eliminar')\n",
    "    else:\n",
    "        h(multiconjunto).remove(elemento)\n",
    "        \n",
    "\n",
    "\n",
    "mc = elimina(mc, 5)\n",
    "mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dado un multiconjunto y un elemento devuelva si el elemento pertenece al multiconjunto\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva si el primero es subconjunto del segundo\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva si son iguales\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def pertenece(multiconjunto, elemento):\n",
    "    \"\"\"\n",
    "    Devuelve si el elemento pertenece al multiconjunto\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto -- multiconjunto devuelto por la función creada anteriormente\n",
    "        elemento -- elemento a determinar si pertenece\n",
    "    \"\"\"\n",
    "\n",
    "def subconjunto(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve si multiconjunto1 es subconjunto de multiconjunto2\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "\n",
    "def iguales(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve si multiconjunto1 es igual a multiconjunto2\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "\n",
    "print(pertenece(mc, 1))\n",
    "print(subconjunto(multiconjunto([1,3,4]), mc))\n",
    "print(iguales(multiconjunto([1,3,4]), mc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su unión\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su intersección\n",
    "### TODO: Crear una función que dados dos multiconjuntos devuelva su diferencia\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def union(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la unión de los multiconjuntos\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "\n",
    "def interseccion(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la intersección de los multiconjuntos\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "\n",
    "def diferencia(multiconjunto1, multiconjunto2):\n",
    "    \"\"\"\n",
    "    Devuelve la diferencia de los multiconjuntos\n",
    "    \n",
    "    Argumentos:\n",
    "        multiconjunto1 -- multiconjunto devuelto por la función creada anteriormente\n",
    "        multiconjunto2 -- multiconjunto devuelto por la función creada anteriormente\n",
    "    \"\"\"\n",
    "\n",
    "print(union(multiconjunto([1,3,4]), mc))\n",
    "print(interseccion(multiconjunto([1,3,4]), mc))\n",
    "print(diferencia(mc, multiconjunto([1,2,3,4])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Singular Value Decomposition\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad para usar Singular Value Decomposition para comprimir una imagen.\n",
    "\n",
    "**Objetivos**\n",
    "- Usar `Python`\n",
    "- Entender los fundamentos de `SVD`.\n",
    "\n",
    "**Problema:** Usar `SVD` para comprimir una imagen en blanco y negro."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La imagen que deberas usar es la siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "%matplotlib inline\n",
    "\n",
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deberas crear tu propia función para calcular el error de reconstrucción, que viene definido por:\n",
    "\n",
    "$$SSE =  \\sum_{n}^{i=1}  \\begin{Vmatrix}x_{i} -  \\widehat{x}_i \\end{Vmatrix} ^2 $$\n",
    "\n",
    "Donde:\n",
    "\n",
    "- $x_i$ son los valores de la matriz original X\n",
    "- $\\widehat{x}_i$ son los valores de la matriz reconstruida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para calcular el error de reconstrucción\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def sse_score(X, X_hat):\n",
    "    \"\"\"\n",
    "    Función para calcular el error de reconstrucción\n",
    "    \n",
    "    Argumentos:\n",
    "        X -- Matriz Original\n",
    "        X_hat -- Matriz Reconstruida\n",
    "        \n",
    "    Ejemplo:\n",
    "        X = np.array([[1, 2], [3, 4]])\n",
    "        X_hat = np.array([[1.01, 1.75], [2.81, 3.99]])\n",
    "        sse = sse_score(X, X_hat) # -> 0.09879\n",
    "    \"\"\"\n",
    "    for each X "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que ya tenemos la función `sse` hecha, podemos pasar a construir la función que ejecutará `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para ejecutar SVM\n",
    "### Tiene como entrada una matriz X\n",
    "### Devuelve U, s, Vt\n",
    "\n",
    "### Hint: S debe ser una matriz diagonal\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def svm(X):\n",
    " \n",
    "         X = np.array([[1, 2], [3, 4]])\n",
    "         U, S, Vt = svm(X)  \n",
    "        \n",
    "         U = array([[-0.40455358, -0.9145143 ],\n",
    "                      [-0.9145143 ,  0.40455358]])\n",
    "         S = array([[5.4649857 , 0.        ],\n",
    "                       [0.        , 0.36596619]])   \n",
    "         Vt = array([[-0.57604844, -0.81741556],\n",
    "                      [ 0.81741556, -0.57604844]])          \n",
    "  \n",
    "    from numpy.linalg import svd\n",
    "    return svd(X , full_matrices= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos visto en clase, las matrices obtenidas a partir de `SVM` nos sirven para reconstruir la matriz original `X`. Para ello, construye una función que permita reconstruir la matriz original `X` a partir de `U, s, Vt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para reconstruir la matriz original a partir de U, s, Vt\n",
    "### Tiene como entrada U, s, Vt\n",
    "### Devuelve X_hat\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def reconstruction(U, S, Vt):\n",
    "    \"\"\"\n",
    "    Función que reconstruye la matriz original a partir de U, s, Vt\n",
    "    \n",
    "    Argumentos:\n",
    "        U -- Matriz de Singular Vectors\n",
    "        s -- Matriz de Eigenvalues\n",
    "        Vt -- Matriz de Singular Vectors\n",
    "        \n",
    "    Ejemplo:\n",
    "        U = np.array([[-0.40455358, -0.9145143 ],\n",
    "                      [-0.9145143 ,  0.40455358]])\n",
    "        S = np.array([[5.4649857 , 0.        ],\n",
    "                      [0.        , 0.36596619]])\n",
    "        Vt = np.array([[-0.57604844, -0.81741556],\n",
    "                       [ 0.81741556, -0.57604844]])\n",
    "        X_hat = reconstruction(U, S, Vt)\n",
    "        \n",
    "        # X_hat -> array([[0.99999999, 1.99999998],\n",
    "        #                 [3.00000003, 4.00000001]])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcula el error de reconstrucción usando la función `sse` que has programado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos programado todas las funciones necesarias para realizar `SVM` y medir el error de reconstrucción, podemos proceder a realizar la compresión de la imagen. Esta [página web](http://timbaumann.info/svd-image-compression-demo/) te ayudará a repasar y a entender como calcular la compresión.\n",
    "\n",
    "Debes usar la siguiente imagen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image\n",
    "A = misc.face(gray=True)\n",
    "\n",
    "plt.imshow(A, cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función que recibe una imagen A y devuelve la imagen comprimida\n",
    "### Tiene como entrada A y el número de componentes para realizar la reducción de dimensionalidad\n",
    "### Devuelve la imagen comprimidad, el error de reconstrucción y el ratio de compresión\n",
    "\n",
    "### Hint: Usa las funciones anteriormente construidas\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def image_compression(A, n_components):\n",
    "    \"\"\"\n",
    "    Función para comprimir una imagen A\n",
    "    \n",
    "    Argumentos:\n",
    "        A -- Imagen original\n",
    "        n_components -- Número de componentes\n",
    "        \n",
    "    Ejemplo:\n",
    "        A_hat, sse, comp_ratio = image_compression(A, n_components=50)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafica la imagen original `X` y la imagen reconstruida `X_hat`, y imprime el error de reconstrucción `sse` y el `ratio de compresion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Linear Regression - Least Squares\n",
    "\n",
    "Este ejercicio pondrá a prueba tu habilidad para programar tu propia versión de mínimos cuadrados en Python.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `Pandas` para leer y analizar los datos.\n",
    "- Asegurar los fundamentos matemáticos detrás del método de los mínimos cuadrados.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresión.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repaso\n",
    "\n",
    "Usaremos la versión matricial de la solución de los **métodos de los mínimos cuadrados** para resolver este problema. Como recordatorio, expresamos los coeficientes $w_{LS}$ como un vector, y calculamos ese vector en base a la matriz de entrada $X$ y en base a $y$.<br><br>\n",
    "\n",
    "\n",
    "\n",
    "Como mostramos en clase, la matriz $X$ siempre contiene un vector de valores $1$ en la primera columna. En otras palabras:<br><br>\n",
    "\n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11}  \\\\\n",
    "1 \\  x_{21}  \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "Para dos variables, $X$ tomará esta forma:\n",
    " \n",
    "<center>$\n",
    "X = \\begin{bmatrix}\n",
    "1 \\  x_{11} \\  x_{12} \\\\\n",
    "1 \\  x_{21} \\  x_{22} \\\\\n",
    "\\vdots \\ \\vdots \\\\\n",
    "1 \\ x_{n1} \\  x_{n2}\n",
    "\\end{bmatrix} \n",
    "$</center>\n",
    "\n",
    "### Exploratorio de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (20.0, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Leer los datos\n",
    "tr_path = '~/Descargas/train.csv'\n",
    "data = pd.read_csv(tr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### La función .head() muestras las primeras lineas de los datos\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lista con los nombres de las columnas\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Numero de columnas \n",
    "### Asignar int variable a: ans1\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "ans1=len(data.columns)\n",
    "ans1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Podemos graficar los datos price vs living area - Matplotlib\n",
    "\n",
    "Y = data['SalePrice']\n",
    "X = data['GrLivArea']\n",
    "\n",
    "plt.scatter(X, Y, marker = \"x\")\n",
    "\n",
    "### Anotaciones\n",
    "plt.title(\"Sales Price vs. Living Area (excl. basement)\")\n",
    "plt.xlabel(\"GrLivArea\")\n",
    "plt.ylabel(\"SalePrice\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### price vs year - Pandas\n",
    "\n",
    "data.plot('YearBuilt', 'SalePrice', kind = 'scatter', marker = 'x');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión Lineal\n",
    "\n",
    "Ya que conocemos la ecuación para $w_{LS}$ tenemos todo lo necesario para resolver la regresión lineal. Vamos allá!<br><br>\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{-1}X^T y,$</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para invertir una matriz\n",
    "### Contruye una función que toma como input una matriz\n",
    "### Devuelve la inversa de dicha matriz\n",
    "### TU RESPUESTA ABAJO\n",
    "import numpy as np\n",
    "\n",
    "mat = np.array([[1, 2],\n",
    "                [3 ,4]])\n",
    "\n",
    "def inverse_of_matrix(mat):\n",
    "    \n",
    "    return np.linalg.inv(mat)\n",
    "\n",
    "inverse_of_matrix(mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer los datos\n",
    "\n",
    "Lo primero que debemos hacer es leer los datos, para ello construye una función que reciba el directorio de un archivo .csv `file_path` y lo lea usando `pandas`, la función debe devolver el dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para leer un .csv\n",
    "### La función recibe un file_path y debe devolver el dataframe\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_to_df(file_path):\n",
    "    df = pd.read_csv('~/Descargas/train.csv')\n",
    "    return   df\n",
    "\n",
    "read_to_df(\"~/Descargas.train.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por columnas\n",
    "\n",
    "Queremos construir una función que nos permita obtener los datos de ciertas columnas. Por ello, le pasaremos como argumento un `dataframe` y una lista con los nombres de las columnas que queremos extraer `column_names` y nos devolverá un dataframe con solo esas columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### TODO: Función para extraer los datos de ciertas columnas\n",
    "### Como argumentos, recibe un dataframe `data_frame`y una lista con los nombres de las columnas `column_names`\n",
    "### Devuelve un dataframe con solo las columnas que le hemos especificado\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "data = read_to_df(\"~/Descargas.train.csv\")\n",
    "\n",
    "selected_columns = data.columns.names([\"SalePrice\", \"GrLivArea\",\"YearBuilt\"])\n",
    "\n",
    "def select_columns(data, columns_names):\n",
    "    \n",
    "    return sub_df == data.columns.keys\n",
    "    \n",
    "sub_df = select_columns(data , selected_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset del dataframe por valores\n",
    "\n",
    "El siguiente paso es construir una función que recibe un `data_frame`, el nombre de una columna, un valor mínimo y un valor máximo `cutoffs`. Nos devuelve un dataframe excluyendo las filas donde el valor de la columna indica está fuera de los valores mínimos y máximos que le hemos indicado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para crear un nuevo subset en base a valores\n",
    "### Como argumento recibe un dataframe y una lista de tuples\n",
    "### Tuples: (column_name, min_value, max_value)\n",
    "### Devuelve un dataframe que excluye las filas donde los valores, en la columna que le hemos indicado, exceden los valores\n",
    "### que le hemos indicado\n",
    "### No eliminar la fila si los valores son iguales al min/max valor\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def column_cutoff(data_frame, cutoffs):\n",
    "    \"\"\"Crea un nuevo dataframe en base a unos límites\n",
    "    \n",
    "    Argumentos:\n",
    "        data_frame -- Dataframe Object\n",
    "        cutoffs -- Lista de tuples con el siguiente formato:\n",
    "        (column_name, min_value, max_value)\n",
    "        \n",
    "    Ejemplo:\n",
    "        data_frame = read_into_data_frame('train.csv')\n",
    "        # Remove data points with SalePrice < $50,000\n",
    "        # Remove data points with GrLiveAre > 4,000 square feet\n",
    "        cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "        selected_data = column_cutoff(data_frame, cutoffs)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mínimos Cuadrados / Least Squares\n",
    "\n",
    "Ahora, implementarás la ecuación $w_{LS}$:\n",
    "\n",
    "<center>$w_{LS} = (X^T X)^{−1}X^T y,$</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para resolver la ecuación wLS\n",
    "### Toma como argumentos dos matrices, una para X y otra para y\n",
    "### Asumimos que las matrices tienen las dimensiones correctas\n",
    "\n",
    "### Paso 1: Asegurate que n > d. \n",
    "### Es decir, que el número de observaciones es mayor que el número de dimensiones.\n",
    "### O lo que es lo mismo, que el número de filas de cada matriz sea mayor que el número de columnas\n",
    "### Si no es así, debes transponer las matrices\n",
    "\n",
    "### Paso 2: Debes añadir a la matriz X un vector columna del tamaño (n x 1)\n",
    "\n",
    "### Paso 3: Usa la ecuación de arriba para obtener wLS\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "\n",
    "def least_squares_weights(input_x, target_y):\n",
    "    \"\"\"Resuelve la ecuación para wLS\n",
    "    \n",
    "    Argumentos:\n",
    "        input_x -- Matriz con los datos de entrenamiento\n",
    "        target_y -- Vector con los datos de salida\n",
    "        \n",
    "    Ejemplo:\n",
    "        import numpy as np\n",
    "        training_y = np.array([[208500, 181500, 223500, \n",
    "                                140000, 250000, 143000, \n",
    "                                307000, 200000, 129900, \n",
    "                                118000]])\n",
    "        training_x = np.array([[1710, 1262, 1786, \n",
    "                                1717, 2198, 1362, \n",
    "                                1694, 2090, 1774, \n",
    "                                1077], \n",
    "                               [2003, 1976, 2001, \n",
    "                                1915, 2000, 1993, \n",
    "                                2004, 1973, 1931, \n",
    "                                1939]])\n",
    "        weights = least_squares_weights(training_x, training_y)\n",
    "        \n",
    "        print(weights)  #--> np.array([[-2.29223802e+06],\n",
    "                        #              [ 5.92536529e+01],\n",
    "                        #              [ 1.20780450e+03]])\n",
    "                           \n",
    "        print(weights[1][0]) #--> 59.25365290008861\n",
    "    \n",
    "    Asumimos:\n",
    "        -- target_y es un vector con el mismo número de observaciones que input_x\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing en datos reales\n",
    "\n",
    "Ahora que ya hemos programado todas las funciones necesarias para calcular la regresión lineal vamos a aplicar al conjunto de datos que habíamos seleccionado al principio. \n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "Si tus funciones están correctamente programadas, la siguiente celda correrá sin problemas 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = (\"~/descargas/train.csv\")\n",
    "df = read_to_df(test_path)\n",
    "df_sub = select_columns(df, ['SalePrice', 'GrLivArea', 'YearBuilt'])\n",
    "\n",
    "cutoffs = [('SalePrice', 50000, 1e10), ('GrLivArea', 0, 4000)]\n",
    "df_sub_cutoff = column_cutoff(df_sub, cutoffs)\n",
    "\n",
    "X = df_sub_cutoff['GrLivArea'].values\n",
    "Y = df_sub_cutoff['SalePrice'].values\n",
    "\n",
    "### reshaping for input into function\n",
    "training_y = np.array([Y])\n",
    "training_x = np.array([X])\n",
    "\n",
    "weights = least_squares_weights(training_x, training_y)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_X = np.max(X) + 500\n",
    "min_X = np.min(X) - 500\n",
    "\n",
    "### Choose points evenly spaced between min_x in max_x\n",
    "reg_x = np.linspace(min_X, max_X, 1000)\n",
    "\n",
    "### Use the equation for our line to calculate y values\n",
    "reg_y = weights[0][0] + weights[1][0] * reg_x\n",
    "\n",
    "plt.plot(reg_x, reg_y, color='#58b970', label='Regression Line')\n",
    "plt.scatter(X, Y, c='k', label='Data')\n",
    "\n",
    "plt.xlabel('GrLivArea')\n",
    "plt.ylabel('SalePrice')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementación con sklearn\n",
    "\n",
    "Podemos comprobar como el resultado de nuestro código es exactamente igual al resultado de `sklearn`. Enhorabuena! Has programado tu propia **regresión lineal!!** 😃"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "### SKLearn requiere un array 2-dimensional X y 1 dimensional y.\n",
    "### skl_X = (n,1); skl_Y = (n,)\n",
    "skl_X = df_sub_cutoff[['GrLivArea']]\n",
    "skl_Y = df_sub_cutoff['SalePrice']\n",
    "\n",
    "lr.fit(skl_X,skl_Y)\n",
    "print(\"Intercept:\", lr.intercept_)\n",
    "print(\"Coefficient:\", lr.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Linear Regression - Gradient Descent\n",
    "\n",
    "En este ejercicio resolveras el mismo problema anterior pero usando **Gradient Descent**\n",
    "\n",
    "**Objetivos**:\n",
    "- Asegurar los fundamentos matemáticos detrás del Gradient Descent.\n",
    "\n",
    "**Problema**: Usando datos sobre el precio de la vivienda, intentaremos predecir el precio de una casa en base a la superficie habitable con un modelo de regresión.\n",
    "\n",
    "**Datos:** [Kaggle's House Prices Dataset](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data)\n",
    "\n",
    "**Repaso:**\n",
    "\n",
    "$$ RSS(w) = \\sum_{n=1}^{N}[y_n-f(x_n)]^2 =  \\sum_{n=1}^{N}[y_n- (w_0 + \\sum_{d=1}^{D}w_dx_{nd}) ]^2 .$$\n",
    "\n",
    "Loss function:\n",
    "\n",
    "$$ RSS(w) = \\frac{1}{2}\\sum_{n=1}^{N}[y_n-f(x_n)]^2$$\n",
    "\n",
    "Y lo que queremos es minimizar esta distancia, para que el modelo se acerque lo máximo posible a los valores verdaderos.\n",
    "\n",
    "$$\\nabla RSS(w) = X^T(Xw^t-y)$$\n",
    "\n",
    "En resumen, el gradient descendiente para una regresión lineal, se basa en resolver esta ecuación de forma iterativa:\n",
    "\n",
    "$$w^{t+1} = w^t - \\eta * \\nabla RSS(w)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Leer datos\n",
    "data = pd.read_csv('~/Descargas/train.csv')\n",
    "\n",
    "# Extraer dichas columnas\n",
    "newData = data[['GrLivArea','SalePrice']]\n",
    "print(newData.head())\n",
    "\n",
    "# Contruir x - y\n",
    "x = newData['GrLivArea']\n",
    "y = newData['SalePrice']\n",
    "\n",
    "# Standarizar los datos\n",
    "x = (x - x.mean()) / x.std()\n",
    "x = np.c_[np.ones(x.shape[0]), x] \n",
    "\n",
    "print(\"Shape of X: \", x.shape)\n",
    "print(\"Shape of y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Función para encontrar los valores w usando Gradient Descent\n",
    "### Toma como argumentos: X, y, w, n_iterations, eta\n",
    "### Completa la función añadiendo la loss función y la updating rule\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def gradient_descent(x, y, w, iterations, eta):\n",
    "\n",
    "    \n",
    "    Argumentos:\n",
    "        x -- Matriz con los datos de entrenamiento\n",
    "        y -- Vector con los datos de salida\n",
    "        w -- Vector aleatoriamente inicializado\n",
    "        iterations -- Número de iteraciones\n",
    "        eta -- Learning Rate\n",
    "        \n",
    "    \n",
    "        import numpy as np\n",
    "\n",
    "        eta = 0.01 \n",
    "\n",
    "        iterations = 2000 \n",
    "\n",
    "       \n",
    "        np.random.seed(123)\n",
    "        w0 = np.random.rand(2)\n",
    "        \n",
    "        training_y = np.array([208500, 181500, 223500, \n",
    "                                140000, 250000])\n",
    "        training_x = np.array([[ 1.        ,  0.37020659],\n",
    "                               [ 1.        , -0.48234664],\n",
    "                               [ 1.        ,  0.51483616],\n",
    "                               [ 1.        ,  0.38352774],\n",
    "                               [ 1.        ,  1.29888065]])\n",
    "                            \n",
    "        weights, loss = gradient_descent(training_x, training_y, w0, iterations, eta)\n",
    "        \n",
    "        print(weights[-1])  #--> np.array([183845.82320222  40415.66453324])\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez construida nuestra función para el Gradient Descent podemos usarla para encontrar los valores optimos de $w$. **Prueba a modificar el learning rate para ver la convergencia del Gradient Descent.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Learning rate\n",
    "eta = 0.001 \n",
    "\n",
    "# Número de iteraciones\n",
    "iterations = 1000 #No. of iterations\n",
    "\n",
    "# Seed para inicializar w\n",
    "np.random.seed(123)\n",
    "w0 = np.random.rand(2)\n",
    "\n",
    "weights, loss = gradient_descent(x, y, w0, iterations, eta)\n",
    "\n",
    "print(weights[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hemos creado la siguiente función para ver como Gradient Descent encuentra el resultado final - **Tarda un poco**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# Definir figure\n",
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "plt.title('Sale Price vs Living Area')\n",
    "plt.xlabel('Living Area in square feet (normalised)')\n",
    "plt.ylabel('Sale Price ($)')\n",
    "plt.scatter(x[:,1], y, color='red')\n",
    "line, = ax.plot([], [], lw=2)\n",
    "annotation = ax.text(-1, 700000, '')\n",
    "annotation.set_animated(True)\n",
    "plt.close()\n",
    "\n",
    "# Generar animacion de los datos\n",
    "def init():\n",
    "    line.set_data([], [])\n",
    "    annotation.set_text('')\n",
    "    return line, annotation\n",
    "\n",
    "# Función para la animación\n",
    "def animate(i):\n",
    "    x = np.linspace(-5, 20, 1000)\n",
    "    y = weights[i][1]*x + weights[i][0]\n",
    "    line.set_data(x, y)\n",
    "    annotation.set_text('loss = %.2f e10' % (loss[i]/10000000000))\n",
    "    return line, annotation\n",
    "\n",
    "anim = animation.FuncAnimation(fig, animate, init_func=init,\n",
    "                               frames=300, interval=0, blit=True)\n",
    "\n",
    "anim.save('animation.gif', writer='imagemagick', fps = 30)\n",
    "\n",
    "# Visualizar la animación\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "\n",
    "filename = 'animation.gif'\n",
    "\n",
    "video = io.open(filename, 'r+b').read()\n",
    "encoded = base64.b64encode(video)\n",
    "HTML(data='''<img src=\"data:image/gif;base64,{0}\" type=\"gif\" />'''.format(encoded.decode('ascii')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Opcional) - Calculando similitud entre páginas web\n",
    "\n",
    "Este ejercicio pondrá a prueba tu capacidad para encontrar la similitud entre vectores usando cosine similarity.\n",
    "\n",
    "**Objetivos**:\n",
    "- Usar `Python` + `BeautifulSoup` para \"scrapear\" páginas webs.\n",
    "- Asegurar los fundamentos matemáticos detrás del cosine similarity.\n",
    "\n",
    "**Problema**: Dadas N páginas web, extraer el texto de ellas y determinar la similitud.\n",
    "\n",
    "### Repaso\n",
    "\n",
    "Como recordarás, podemos medir la similitud entre vectores usando la siguiente ecuación:<br>\n",
    "\n",
    "<center>$\\overrightarrow{u} \\cdot \\overrightarrow{v} = |\\overrightarrow{u}||\\overrightarrow{v}| \\cos \\theta $</center>\n",
    "\n",
    "Que podemos reescribir de la siguiente forma:<br>\n",
    "\n",
    "<center>$\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$</center>\n",
    "\n",
    "La **similitud** va a venir dada por el ángulo $\\theta$, que nos indicará lo siguiente:\n",
    "\n",
    "<img src=\"./Images/cosine_sim.png\" width=70%/>\n",
    "\n",
    "### Web scraping\n",
    "\n",
    "La técnica llamada `web scraping` es la utilizada normalmente para extraer contenido de páginas webs y posteriormente procesarlos. Por ejemplo, si quisieramos construir una base de datos para entrenar un modelo con imágenes de ropa para hombres, podríamos intentar \"scrapear\" dicha sección de la página web del El Corte Inglés para conseguir las imágenes (no es tan fácil como suena)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estas librerias deben ser instaladas para hacer este ejercicio\n",
    "!pip install beautifulsoup4\n",
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import lxml\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "import urllib.request\n",
    "\n",
    "url = \"https://es.wikipedia.org/wiki/Canis_lupus_familiaris\"\n",
    "\n",
    "def parse_from_url(url):\n",
    "    \"\"\"\n",
    "    Función para extraer el contenido (raw text) de una página web\n",
    "    \"\"\"\n",
    "    \n",
    "    html = urllib.request.urlopen(url).read()\n",
    "    soup = BeautifulSoup(html, \"html.parser\" )\n",
    "    for script in soup([\"script\", \"style\"]):\n",
    "        script.extract()\n",
    "        \n",
    "    text = soup.get_text()\n",
    "    \n",
    "    # Eliminar saltos de linea\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "parse_from_url(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que reciba una lista de urls\n",
    "### Aplica web scraping a cada una de ellas para extraer el contenido\n",
    "### Y devuelva un diccionario con el contenido por cada url\n",
    "\n",
    "### HINT: Usa la función anterior\n",
    "### NOTE: Suele tardar un poco en extraer el contenido de las paginas web\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def get_content(url_ls):\n",
    "    \"\"\"Extrae el contenido de una lista de urls\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista con urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        url2content = get_content(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Esta función depende de 'parse_from_url()'\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesado\n",
    "\n",
    "Como es lógico, no podemos resolver esta ecuación $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$ usando texto sin más, debemos convertir cada página web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que reciba texto\n",
    "### Y devuelva una lista con el texto separado por espacios\n",
    "### Además del set de la lista\n",
    "### \"hola que que tal\" - [\"hola\", \"que\", \"que\", \"tal\"], {\"hola\", \"que\", \"tal\"}\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"Divide el texto en palabras\n",
    "    \n",
    "    Argumentos:\n",
    "        text -- String\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = \"Hola me llamo llamo Alex y estamos aprendiendo Algebra y estamos bien\"\n",
    "        \n",
    "        tokens_txt, set_txt = tokenizer(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        No uses ningún tokenizer ya implementado (nltk, spacy, ...)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso es crear un conjunto con las palabras de ambas páginas web (unión), por ejemplo:\n",
    "\n",
    "- Los perros son maravillosos...\n",
    "- Los maravillosos años 80...\n",
    "\n",
    "Por tanto, el conjunto para estas dos frases sería `{\"los\", \"perros\", \"son\", \"maravillosos\", \"años\", \"80\"}`. Debemos realizar esto para todas las combinaciones posibles, es decir:\n",
    "\n",
    "- web_1\n",
    "- web_2\n",
    "- web_3\n",
    "\n",
    "En este caso, las combinaciones serían (no importa el orden) `[web_1, web_2]`, `[web_1, web_3]`, `[web_2, web_3]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe una lista de N páginas web\n",
    "### Y calcula todas las combinaciones posibles entre ellas, no importa el orden\n",
    "### [web_1, web_2, web_3, ...]\n",
    "### Devuelve una lista de tuples con las combinaciones [(web_1, web_2), (web_1, web_3), ...]\n",
    "\n",
    "# HINT: Puedes implementar esta función como quieras pero la librería itertools \n",
    "#       proporciona una función llamada `combinations` para realizar esta tarea.\n",
    "\n",
    "### TU RESPUESTA ABAJO\n",
    "import itertools\n",
    "    \n",
    "def combinations(url_ls):\n",
    "    \"\"\"Calcula todas las combinaciones posibles entre los elementos de una lista\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Lista de urls\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        permutation = combinations(url_ls)  \n",
    "    \n",
    "    Requerimientos:\n",
    "        Puedes implementar esta función como quieras pero la librería itertools \n",
    "        proporciona una función llamada `combinations` para realizar esta tarea.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe una lista con tuples\n",
    "### [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "### Y devuelve una lista con la union de los conjuntos\n",
    "### [({'que', 'hola', 'es', 'guay'}), ({'que', 'hola', 'madrid', 'la', 'es'})]\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "def union(comb_ls):\n",
    "    \"\"\"Calcula la unión por cada tuple de una lista \n",
    "    \n",
    "    Argumentos:\n",
    "        comb_ls -- Lista de tuples\n",
    "        \n",
    "    Ejemplo:\n",
    "        comb_ls = [({'que', 'hola'}, {'que', 'es', 'guay'}), ({'que', 'hola'}, {'madrid', 'la', 'es'})]\n",
    "        \n",
    "        union_ls = union(comb_ls)  # -> [{'es', 'que', 'hola', 'guay'}, {'es', 'que', 'hola', 'madrid', 'la'}]\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que tenemos una lista de conjuntos por cada par de páginas web, podemos convertir el texto de la página web a un vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set2vector(tokens_web1, tokens_web_2, set_web1, set_web2):\n",
    "    \"\"\"\n",
    "    Función para convertir un conjunto a vector\n",
    "    \n",
    "    Argumentos:\n",
    "        tokens_web1 -- Contenido tokenizado de página web 1\n",
    "        tokens_web_2 -- Contenido tokenizado de página web 2\n",
    "        set_web1 -- Conjunto de palabras de la página web 1\n",
    "        set_web2 -- Conjunto de palabras de la página web 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "        tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "        set_web1 = {\"hola\", \"que\", \"tal\"}\n",
    "        set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "        union_ls = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  \n",
    "        \n",
    "    Requerimientos:\n",
    "        Depende de la función `union()`\n",
    "    \"\"\"\n",
    "    \n",
    "    # Unimos los conjuntos\n",
    "    join_set = union([(set_web1, set_web2)])[0]\n",
    "    \n",
    "    web1_array = []\n",
    "    web2_array = [] \n",
    "\n",
    "    for word in join_set:\n",
    "        if word in tokens_web1:\n",
    "            web1_array.append(1)\n",
    "        else:\n",
    "            web1_array.append(0)\n",
    "        if word in tokens_web_2:\n",
    "            web2_array.append(1)\n",
    "        else:\n",
    "            web2_array.append(0)\n",
    "\n",
    "    return web1_array, web2_array\n",
    "\n",
    "tokens_web1 = [\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"]\n",
    "tokens_web_2 = [\"hola\", \"me\", \"llamo\"]\n",
    "set_web1 = {\"hola\", \"que\", \"tal\", \"soy\", \"Alex\"}\n",
    "set_web2 = {\"hola\", \"me\", \"llamo\"}\n",
    "web1_array, web2_array = set2vector(tokens_web1, tokens_web_2, set_web1, set_web2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(web1_array, web2_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "Por último, ya podemos implementar la ecuación: $\\cos \\theta = \\frac{\\overrightarrow{u} \\cdot \\overrightarrow{v}}{|\\overrightarrow{u}||\\overrightarrow{v}|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: Escribe una función que recibe dos vectores, u y v\n",
    "### Y devuelva la similaridad entre ambos vectores\n",
    "###\n",
    "### Paso 1: Si u y v son listas -> Convertirlo a arrays\n",
    "###\n",
    "### Paso 2: Calcula la similaridad entre ambos vectores\n",
    "### TU RESPUESTA ABAJO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"Calcula la similaridad entre dos vectores\n",
    "    \n",
    "    Argumentos:\n",
    "        u -- Vector 1\n",
    "        v -- Vector 2\n",
    "        \n",
    "    Ejemplo:\n",
    "        u = np.array([1, 2, 3])\n",
    "        v = np.array([3, 2, 1])\n",
    "        \n",
    "        similarity = cosine_similarity(u, v)  # -> 0.71428\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def websites_sim(url_ls):\n",
    "    \"\"\"Función para calcular la similaridad entre páginas web\n",
    "    \n",
    "    Argumentos:\n",
    "        url_ls -- Listas de páginas web\n",
    "        \n",
    "    Ejemplo:\n",
    "        url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "        'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "        'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "        \n",
    "        similarity_ls = websites_sim(url_ls)  \n",
    "    \"\"\"\n",
    "    \n",
    "    url2content = get_content(url_ls)\n",
    "    \n",
    "    # Creamos un diccionario donde cada url tendrá su contenido tokenizado y su conjunto\n",
    "    url_dict = {}\n",
    "    for url, content in url2content.items():\n",
    "        toks, sets = tokenizer(content)\n",
    "        url_dict[url] = {'tokens': toks,\n",
    "                        'unique_tokens': sets}\n",
    "    \n",
    "    # Calculamos todas las combinaciones posibles de las direcciones de las páginas web\n",
    "    comb_ls = combinations(url_ls)\n",
    "\n",
    "    # Usando comb_ls y la función `set2vector()` convertimos cada página web a vectores\n",
    "    print(\"Similaridad: \")\n",
    "    for el in comb_ls:\n",
    "        # Obtenemos los tokens y el conjunto para cada página web\n",
    "        token_1 = url_dict[el[0]]['tokens']\n",
    "        token_2 = url_dict[el[1]]['tokens']\n",
    "        set_1 = url_dict[el[0]]['unique_tokens']\n",
    "        set_2 = url_dict[el[1]]['unique_tokens']\n",
    "        array_web1, array_web2 = set2vector(token_1, token_2, set_1, set_2)\n",
    "        similarity = cosine_similarity(array_web1, array_web2)\n",
    "        \n",
    "        print(\"{} vs {} - {}\".format(el[0], el[1], round(similarity, 3)))\n",
    "\n",
    "                      \n",
    "url_ls = ['https://es.wikipedia.org/wiki/Canis_lupus_familiaris', \n",
    "'https://es.wikipedia.org/wiki/Canis_lupus',\n",
    "'https://es.wikipedia.org/wiki/Felis_silvestris_catus']\n",
    "\n",
    "similarity_ls = websites_sim(url_ls) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
